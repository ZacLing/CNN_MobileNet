{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e1aa2aa-872a-4653-ae03-19f6047700e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ad2f9f1-8c86-4750-9c9a-e6e9dabe1483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "# 加载预训练的 MobileNet 模型，不包括顶层\n",
    "base_model = MobileNet(weights='imagenet', include_top=False)\n",
    "\n",
    "# 添加新的顶层\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "predictions = Dense(2, activation='sigmoid')(x)  # 使用sigmoid激活函数\n",
    "\n",
    "# 定义新的模型\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# 冻结所有原始 MobileNet 的层\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy')  # 使用二元交叉熵作为损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "32a02a7f-4d94-42a1-9485-f3ba16c23ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18 images belonging to 2 classes.\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0041\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0062\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0364\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0149\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0197\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0369\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0122\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0057\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0374\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0610\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0813\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0110\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0235\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0043\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0486\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0149\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0092\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0051\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0034\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0195\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0094\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0083\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0120\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0194\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0071\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0102\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0078\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe14811c6a0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据增强\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# 数据生成器\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/root/autodl-tmp/train',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=2,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "model.fit(train_generator, steps_per_epoch=1, epochs=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9d9c363a-1284-4830-b3e3-f67d8ec47ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bound = 0.95\n",
    "\n",
    "def predict_image(image_path):\n",
    "    img = load_img(image_path, target_size=(224, 224))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "    predictions = model.predict(img_array)\n",
    "\n",
    "    if predictions[0][0] < bound and predictions[0][1] < bound:\n",
    "        return 'Nothing'\n",
    "    elif predictions[0][0] >= bound:\n",
    "        return 'box'\n",
    "    elif predictions[0][1] >= bound:\n",
    "        return 'tea'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f3430859-04c9-4312-8d38-08f1711bde5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nothing'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_image('test/cat1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec31385-3162-421c-9e92-ca2e11892ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
